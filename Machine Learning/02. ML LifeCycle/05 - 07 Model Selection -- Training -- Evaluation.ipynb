{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24566be",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "    The process of choosing the best algorithm or model architecture that is most suitable for a given problem.\n",
    "    \n",
    "    It's crucial because different algorithms or models might perform differently on various datasets or tasks.\n",
    "    \n",
    "    In the real world, the problem is defined as to be classified to a certain category or to predict the continuous value.\n",
    "    \n",
    "    The goal is to identify the model that generalizes well to unseen data and provides the best performance metrics, such as accuracy, precision, recall, or others, depending on the problem type (classification, regression, etc.)\n",
    "    \n",
    "    We main going to focus on Classification problem.\n",
    "    \n",
    "    Classification Algorithm consists off:\n",
    "        Parametric Model : \n",
    "            Logistic Regression\n",
    "            Gaussian Naive Bayes\n",
    "            \n",
    "        Nonparametric Models :       \n",
    "            K-Nearest Neighbors (KNN)\n",
    "            Decision Trees\n",
    "            Random Forest\n",
    "            Support Vector Machines (SVM)\n",
    "            \n",
    "---            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b88b22",
   "metadata": {},
   "source": [
    "    Deep dive into these models.\n",
    "    \n",
    "    Logistic Regression : \n",
    "    Gaussian Naive Bayes :\n",
    "    K-Nearest Neighbors (KNN) :\n",
    "    Decision Trees :\n",
    "    Random Forest :\n",
    "    Support Vector Machines (SVM) : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affeca5",
   "metadata": {},
   "source": [
    "    Rough example of Ensemble Model!\n",
    "    \n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "rf  = RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "nb = CategoricalNB()\n",
    "xgb = XGBClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "model_list  = [rf, lr,nb,xgb,knn]\n",
    "model_name = ['rf','lr','nb','xgb','knn']\n",
    "model_output  = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3,\n",
    "                                                   random_state=49,\n",
    "                                                   stratify=y)\n",
    "model_dfs = {}\n",
    "for i, j in zip(model_list, model_name):\n",
    "    model_dfs[j] = i.fit(train_x, train_y)\n",
    "    \n",
    "for i in model_dfs.keys():\n",
    "    pred  = model_dfs[i].predict(test_x)\n",
    "    print('Model Name %s'%i)\n",
    "    print(classification_report(test_y, pred))    \n",
    "```    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
